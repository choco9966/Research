{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b697222cb6f4b949a19fa3d83f7407e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6470656\n",
      "2.5508668\n",
      "2.5278397\n",
      "2.5204988\n",
      "2.5175366\n",
      "2.5162337\n",
      "2.5157301\n",
      "2.5156796\n",
      "2.5159123\n",
      "2.5163348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "class MatrixFactorization():\n",
    "    def __init__(self, R, k, learning_rate, reg_param, epochs, verbose=False):\n",
    "        '''\n",
    "        R : Rating Matrix  \n",
    "        k : Latent size\n",
    "        learning_rate : learning_rate\n",
    "        reg_param : regulazation parameter\n",
    "        '''\n",
    "        self._R = R\n",
    "        self._num_users, self._num_items = R.shape\n",
    "        self._k = k\n",
    "        self._learning_rate = learning_rate\n",
    "        self._reg_param = reg_param\n",
    "        self._epochs = epochs\n",
    "        self._verbose = verbose\n",
    "        self.build_graph()\n",
    "\n",
    "    def build_graph(self):\n",
    "        '''\n",
    "        U : User Matrix \n",
    "        I : Item Matrix \n",
    "        bu : User Bias\n",
    "        bi : Item Bias\n",
    "        bg : global bias\n",
    "        '''\n",
    "        self.U = tf.Variable(tf.random.normal([self._num_users, self._k]), dtype=tf.float32)\n",
    "        self.I = tf.Variable(tf.random.normal([self._num_items, self._k]), dtype=tf.float32)\n",
    "        self.bu = tf.Variable(tf.zeros([self._num_users]), dtype=tf.float32)\n",
    "        self.bi = tf.Variable(tf.zeros([self._num_items]), dtype=tf.float32)\n",
    "        self.bg = tf.constant([np.mean(self._R[np.where(self._R != 0)])],dtype=tf.float32)\n",
    "\n",
    "\n",
    "    def loss(self, i, j):\n",
    "        '''\n",
    "        Cost(i, j) = (r(i, j) - ri_hat(i, j))**2 + lambda * (||bias_u|| + ||bias_i||)\n",
    "        '''\n",
    "        self.error = (self._R[i, j] - tf.tensordot(self.U[i] , tf.transpose(self.I[j]), axes=1) - self.bu[i] - self.bi[j] - self.bg) ** 2\n",
    "        self.error += self._reg_param * (tf.reduce_sum(self.bu) + tf.reduce_sum(self.bi))\n",
    "        return self.error\n",
    "    \n",
    "    def gradientdescent(self, i, j):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_value = self.loss(i, j)\n",
    "        return tape.gradient(loss_value, [self.U, self.I, self.bu, self.bi])\n",
    "            \n",
    "    def fit(self):\n",
    "        self.build_graph()\n",
    "        self.training_process = []\n",
    "        xi, yi = self._R.nonzero()\n",
    "        for epoch in tqdm(range(self._epochs)):\n",
    "            '''\n",
    "            calculate only non zero values\n",
    "            '''\n",
    "            for i, j in zip(xi, yi):\n",
    "                if self._R[i, j] > 0:\n",
    "                    du, di, dbu, dbi = self.gradientdescent(i, j)\n",
    "                    self.bu[i].assign((self.bu[i] - self._learning_rate * dbu)[0])\n",
    "                    self.bi[j].assign((self.bi[j] - self._learning_rate * dbi)[0])\n",
    "                    self.U[i].assign((self.U[i] - self._learning_rate * du)[0])\n",
    "                    self.I[j].assign((self.I[j] - self._learning_rate * di)[0])\n",
    "                else:\n",
    "                    continue\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(self.cost())\n",
    "            \n",
    "    def get_complete_matrix(self):\n",
    "        return tf.tensordot(self.U , tf.transpose(self.I), axes=1) + tf.expand_dims(model.bi, 0) + tf.expand_dims(model.bu, 1) + self.bg\n",
    "        \n",
    "    def cost(self):\n",
    "        xi, yi = self._R.nonzero()\n",
    "        predicted = self.get_complete_matrix()\n",
    "        cost = 0\n",
    "        for x, y in zip(xi, yi):\n",
    "            cost += pow(self._R[x, y] - predicted[x, y], 2)\n",
    "        return np.sqrt(cost / len(xi))\n",
    "    \n",
    "if __name__ == \"__main__\": # 이름을 main으로 설정해서 여기 안에서 테스트 하는 용도임. 이렇게 하면 다른 곳에 불러올 때 이 안은 사용 안함\n",
    "\n",
    "    R = np.array([\n",
    "        [1, 0, 0, 1, 3],\n",
    "        [2, 0, 3, 1, 1],\n",
    "        [1, 2, 0, 5, 0],\n",
    "        [1, 0, 0, 4, 4],\n",
    "        [2, 1, 5, 4, 0],\n",
    "        [5, 1, 5, 4, 0],\n",
    "        [0, 0, 0, 1, 0],\n",
    "    ])\n",
    "    model = MatrixFactorization(R, k=3, learning_rate=0.01, reg_param=0.01, epochs=100, verbose=True)\n",
    "    model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
